{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Quiz1\n"
      ],
      "metadata": {
        "id": "vzYMQ86cBlRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "8DprmgJBBjLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def timer(func): # timer using decorator\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    computation_time = end_time - start_time\n",
        "    print(f\"Execution time of {func.__name__}: {computation_time} seconds\")\n",
        "    return result\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "zLgim_BcBjKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time"
      ],
      "metadata": {
        "id": "yAxfQrz8BjH2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_b = 1\n",
        "true_w = 2\n",
        "N = 100\n",
        "\n",
        "np.random.seed(42)\n",
        "\n",
        "#N개 난수 생성, 정규분포 따름\n",
        "x = np.random.rand(N,1)\n",
        "epsilon = 0.1*np.random.rand(N,1)\n",
        "y = true_b + true_w*x + epsilon\n",
        "\n",
        "\n",
        "# trainset, validationset\n",
        "idx = np.arange(N)\n",
        "split_index = int(N*0.8)\n",
        "train_index = idx[:split_index]\n",
        "val_index = idx[split_index:]\n",
        "\n",
        "x_train, y_train = x[train_index], y[train_index]\n",
        "\n",
        "x_val, y_val = x[val_index], y[val_index]\n",
        "\n",
        "\n",
        "#create tensor at CPU\n",
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "y_train_tensor = torch.as_tensor(y_train)\n",
        "\n",
        "#create tensor at GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "##GPU로 보냄\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)\n",
        "\n",
        "\n",
        "from torch import nn, optim\n",
        "\n",
        "@timer\n",
        "def train_model_optim(lr = 0.1, epochs = 1000):\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "    parameters = [b,w]\n",
        "    optimizer = optim.SGD(parameters, lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        #loss\n",
        "        y_hat = b + w * x_train_tensor\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "\n",
        "\n",
        "        #gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return w, b\n",
        "\n",
        "\n",
        "\n",
        "train_w, train_b = train_model_optim()\n",
        "print(train_w, train_b)\n",
        "\n",
        "\n",
        "\n",
        "###1\n",
        "x_val_tensor = torch.as_tensor(x_val).to(device)\n",
        "y_val_tensor = torch.as_tensor(y_val).to(device)\n",
        "\n",
        "\n",
        "mse_loss = nn.MSELoss()\n",
        "y_hat = train_b + train_w * x_val_tensor\n",
        "loss = (mse_loss(y_hat, y_val_tensor))\n",
        "print(loss)\n"
      ],
      "metadata": {
        "id": "M5EqCz_uBjFj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "S-try3hPBjDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "670C9LgIBjBD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m0ySFDhQBi-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pb_PhglrBi87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yhG8I6KFBi6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7C0po5l3Bi3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quiz2\n"
      ],
      "metadata": {
        "id": "vMS-oJmRBoI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "def timer(func): # timer using decorator\n",
        "  def wrapper(*args, **kwargs):\n",
        "    start_time = time.time()\n",
        "    result = func(*args, **kwargs)\n",
        "    end_time = time.time()\n",
        "    computation_time = end_time - start_time\n",
        "    print(f\"Execution time of {func.__name__}: {computation_time} seconds\")\n",
        "    return result\n",
        "  return wrapper"
      ],
      "metadata": {
        "id": "V3fjVBUKdx5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open('./sample_data/quiz_data.pkl', \"rb\") as fr:\n",
        "    data = pickle.load(fr)\n",
        "\n"
      ],
      "metadata": {
        "id": "9j2ftqgkGoC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "N = 100\n",
        "\n",
        "idx = np.arange(N)\n",
        "\n",
        "split_index = int(N*0.8)\n",
        "train_index = idx[:split_index]\n",
        "val_index = idx[split_index:]\n",
        "\n",
        "x_train, y_train = data['x'][train_index], data['y'][train_index]\n",
        "x_val, y_val = data['x'][val_index], data['y'][val_index]\n",
        "\n"
      ],
      "metadata": {
        "id": "bKdE3paHGpI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_tensor = torch.as_tensor(x_train)\n",
        "y_train_tensor = torch.as_tensor(y_train)\n",
        "x_val_tensor = torch.as_tensor(x_val)\n",
        "y_val_tensor = torch.as_tensor(y_val)\n",
        "\n",
        "x_mean = x_train_tensor.mean()\n",
        "x_std = x_train_tensor.std()\n",
        "x_train_tensor = (x_train_tensor - x_mean) / x_std\n",
        "\n",
        "y_mean = y_train_tensor.mean()\n",
        "y_std = y_train_tensor.std()\n",
        "y_train_tensor = (y_train_tensor - y_mean) / y_std\n",
        "\n",
        "x_mean = x_val_tensor.mean()\n",
        "x_std = x_val_tensor.std()\n",
        "x_val_tensor = (x_val_tensor - x_mean) / y_std\n",
        "\n",
        "y_mean = y_val_tensor.mean()\n",
        "y_std = y_val_tensor.std()\n",
        "y_val_tensor = (y_val_tensor - y_mean) / y_std\n",
        "\n",
        "#create tensor at GPU\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(device)\n",
        "##GPU로 보냄\n",
        "x_train_tensor = torch.as_tensor(x_train).to(device)\n",
        "y_train_tensor = torch.as_tensor(y_train).to(device)\n",
        "x_val_tensor = torch.as_tensor(x_val).to(device)\n",
        "y_val_tensor = torch.as_tensor(y_val).to(device)\n"
      ],
      "metadata": {
        "id": "RVcx8SiHGqUy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@timer\n",
        "def train_model_optim(lr = 0.5, epochs = 1000):\n",
        "    w1 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w2 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w3 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w4 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    w5 = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "    b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "\n",
        "    parameters = [b,w1, w2, w3, w4, w5]\n",
        "    optimizer = optim.SGD(parameters, lr=lr)\n",
        "    mse_loss = nn.MSELoss()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        #loss\n",
        "        y_hat = b + w1 * x_train_tensor + w2 * (x_train_tensor ** 2) + w3 * (x_train_tensor ** 3) + w4 * (x_train_tensor ** 4) + w5 * (x_train_tensor ** 5)\n",
        "        loss = mse_loss(y_hat, y_train_tensor)\n",
        "        # print(\"loss: \", loss)\n",
        "\n",
        "        #gradient\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "    return w1, w2, w3, w4,w5, b"
      ],
      "metadata": {
        "id": "ImkvVZnaGyjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_w1, train_w2,train_w3,train_w4, train_w5,train_b = train_model_optim()\n",
        "print(train_w1, train_w2,train_w3,train_w4,train_w5, train_b)"
      ],
      "metadata": {
        "id": "Gcq4R9OAG0Fs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mse_loss = nn.MSELoss()\n",
        "num = 10\n",
        "loss_sum = 0\n",
        "lr = 0.5\n",
        "epochs = 2000\n",
        "\n",
        "for i in range(num):\n",
        "  train_w1, train_w2, train_w3, train_w4, train_w5, train_b = train_model_optim(lr=lr, epochs=epochs)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    y_hat = train_b + train_w1 * x_val_tensor + train_w2 * (x_val_tensor ** 2) + train_w3 * (x_val_tensor ** 3) + train_w4 * (x_val_tensor ** 4) + train_w5 * (x_val_tensor ** 5)\n",
        "    loss = mse_loss(y_hat, y_val_tensor)\n",
        "    loss_sum += loss.item()  # MSE 값을 누적\n",
        "    print(\"loss: \", loss)\n",
        "\n",
        "average = loss_sum / num\n",
        "print(\"Average loss: \", average)"
      ],
      "metadata": {
        "id": "mPLLTR0OG1p4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rkmfIHRjG3Zn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}